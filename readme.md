# Denoiser & Colorizer - U-Net Modification Study

> Comparative analysis of U-Net architectural modifications for image denoising and color restoration.

**Team 3 - Deep Learning Project**

| Name                      | NIM       | Task                          | Status  |
| ------------------------- | --------- | ----------------------------- | ------- |
| Rui Krisna                | C14230277 | Feature Pyramid Network (FPN) | ‚úÖ Done |
| Bryan Alexander Limanto   | C14230114 | Residual Blocks               | ‚úÖ Done |
| Satrio Adi Rinekso        | C14230112 | Controlled Cross-Feedback     | ‚úÖ Done |
| Reynard Sebastian Hartono | C14230155 | Depthwise Separable Conv      | ‚úÖ Done |
| Juan Matthew Davidson     | C14230124 | Attention Gates               | ‚¨ú TODO |

**Advisor:** Liliana, S.T., M.Eng., Ph.D.

---

## üì¶ Resources

- **Code:** [GitHub Repository](https://github.com/Asep-Ireng/denoiser_colorizer)
- **Weights:** [Hugging Face Models](https://huggingface.co/Asep-Ireng/Denoiser_Colorizer)
- **Dataset:** COCO Animals (15,000 images filtered from COCO 2017)

---

## üöÄ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/Asep-Ireng/denoiser_colorizer.git
cd denoiser_colorizer
```

### 2. Download Weights

```bash
pip install huggingface_hub
huggingface-cli download Asep-Ireng/Denoiser_Colorizer --local-dir weights/
```

### 3. Install Dependencies

```bash
pip install torch torchvision gradio numpy pillow tqdm timm
```

### 4. Run Gradio App

```bash
python app.py
```

---

## üìä Results

### FPN Modification (by Rui Krisna)

| Model             | œÉ=15      | œÉ=25      | œÉ=50      | Average   |
| ----------------- | --------- | --------- | --------- | --------- |
| Baseline (DRUNet) | 32.80     | 30.07     | 25.92     | 29.60     |
| FPN Arch-Only     | 19.47     | 18.96     | 17.77     | 18.73     |
| **FPN Trained**   | **32.99** | **30.56** | **27.45** | **30.33** |

**Key Finding:** FPN-enhanced denoiser achieves **+0.73 dB PSNR improvement** over baseline, with best gains at high noise (+1.53 dB at œÉ=50).


### Residual Blocks Modification (by Bryan Alexander Limanto)


| Model Name        |  œÉ=15  |  œÉ=25  |  œÉ=50  | Average   |
| ----------------- | -------| -------| -------| --------- |
| Plain U-Net       | 30.31  | 28.06  | 24.91  | 27.76     |
| Residual U-Net    | 31.62  | 29.18  | 26.11  | 28.97     |
| DRUNet (Baseline) | 31.86  | 29.16  | 25.12  | 28.71 	   |

**Key Finding:** The Residual U-Net outperforms the DRUNet baseline with **a +0.26 dB average improvement**. Most notably, it demonstrates superior robustness at high noise levels, achieving a significant **+0.99 dB gain at œÉ=50** compared to the baseline.


### DSC Modification (by Reynard Sebastian Hartono)

* Base Params: 32,638,656
* DSC Params : 4,952,768
* Parameters Reduction  : 84.83%
* Base Inference: 236.17 ms
* DSC Inference : 68.73 ms

| Model             | œÉ=15      | œÉ=25      | œÉ=50      | Average   |
| ----------------- | --------- | --------- | --------- | --------- |
| **Baseline**      | 32.26     | 29.60     | 25.62     | **29.16** |
|DSC_Epoch5         | 31.35     | 28.98     | 26.01     | 28.78     |
|DSC_Epoch10        | 31.64     | 29.23     | 26.19     | 29.02     |
|DSC_Epoch15        | 31.70     | 29.29     | 26.26     | 29.08     |
|DSC_Epoch20        | 31.74     | 29.33     | 26.29     | 29.12     |
| **DSC_Best**      | 31.61     | 29.20     | 26.18     | **29.00** |

**Key Findings:** 
* The DSC version of the denoiser achieves less PNSR score (with the average being -0.16 dB PSNR reduction in this evaluation). This is expected considering the reduction of parameters (which in turn causes less inference time), which causes this reduction to be insignificant and can be considered as a worthwile trade-off.
* With a high noise input (specifically at level œÉ=50), the DSC version appears to be winning in terms of PSNR score in every epoch checkpoint. This interesting finding may be caused by the reduction of parameters, which in turn reduces the risk of overfitting and acting as a regularization step. These conditions caused the DSC model to produce a smoother reconstruction of high-noise images.

###  Controlled Cross-Field Feedback Modification (by Satrio Adi Rinekso)

Total Parameters:  16,390,404

Inference Speed: 946.49 ms ms Tested on CPU

| Model             | œÉ=15      | œÉ=25      | œÉ=50      | Average   |
| ----------------- | --------- | --------- | --------- | --------- |
| Baseline          | 15.03      |  14.35     | 12.35      | 13.87      |
| Controled Cross-Field               | 23.46     | 23.43     | 16.39     | 21.09     |

**Key Finding:** The Controlled Cross-Field Feedback mechanism implements a dual-task architecture that simultaneously performs image denoising and colorization, a far more complex challenge than the single-task methods used in other modifications. By utilizing semantic information from the colorization task to guide the denoising process, the model achieves a significant average improvement of 21.09 dB (+7.22 dB gain) over the baseline. 

## üèóÔ∏è Architecture

### Base Model

- **Denoiser:** DRUNet (UNetRes) - grayscale denoising
- **Colorizer:** DDColor - transformer-based colorization

### Modifications Being Studied

1. **Residual Blocks**  ‚úÖ - Improve gradient flow
2. **Attention Gates** - Focus on relevant regions
3. **Cross-Feedback**  ‚úÖ - Share features between denoiser/colorizer
4. **Feature Pyramid Network (FPN)** ‚úÖ - Multi-scale feature fusion
5. **Depthwise Separable Conv**  ‚úÖ - Reduce parameters

---

## üìÅ Project Structure

```
denoiser_colorizer/
‚îú‚îÄ‚îÄ app.py                  # Gradio UI
‚îú‚îÄ‚îÄ train_fpn.py            # FPN training script
‚îú‚îÄ‚îÄ evaluate.py             # PSNR evaluation
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ denoiser/           # Baseline DRUNet
‚îÇ   ‚îú‚îÄ‚îÄ colorizer/          # DDColor
‚îÇ   ‚îî‚îÄ‚îÄ modified/           # FPN-enhanced UNet
‚îú‚îÄ‚îÄ weights/                # Model weights (download from HF)
‚îî‚îÄ‚îÄ utils/                  # Dataset utilities
```

---

## üë• Team Checklist

### For Each Modification:

- [ ] **Create model file** in `models/modified/`
- [ ] **Add training script** (e.g., `train_xxx.py`)
- [ ] **Run evaluation** using `evaluate.py`
- [ ] **Update this README** with results table
- [ ] **Commit and push** to GitHub
- [ ] **Upload weights** to Hugging Face

### How to Add Your Modification:

1. Copy baseline model to `models/modified/`
2. Implement your modification
3. Train using your training script
4. Run `python evaluate.py --num_images 100`
5. Add your results to this README
6. Push code and weights

---

## üìÑ References

- **DRUNet:** [DPIR Paper](https://github.com/cszn/DPIR)
- **DDColor:** [DDColor Paper](https://github.com/piddnad/DDColor)
- **COCO Dataset:** [COCO 2017](https://cocodataset.org/)
- **FPN:** [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144)

---

## üìù License

MIT License
